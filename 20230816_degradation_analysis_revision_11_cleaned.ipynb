{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bddf45b8",
   "metadata": {},
   "source": [
    "# Degradation Data Clustering\n",
    "\n",
    "Titan Hartono (titan.hartono@helmholtz-berlin.de)\n",
    "Data collected and cleaned from: Paolo Graniero, Hans Koebler\n",
    "\n",
    "ver 20230816\n",
    "\n",
    "## 1. Import libraries and load the dataset\n",
    "\n",
    "### 1.1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac5247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:35:40.030018Z",
     "start_time": "2023-08-16T13:35:40.009985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install the following packages if they haven't been installed\n",
    "\n",
    "# pip install \"dask[complete]\"\n",
    "# pip install \"-U kaleido\"\n",
    "# pip install \"kaleido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74efe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:35:43.884367Z",
     "start_time": "2023-08-16T13:35:40.684958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all the packages needed for the notebook to run\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "# import rdkit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "from IPython.display import display_html\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle5 as pickle\n",
    "import dask\n",
    "from PIL import ImageColor\n",
    "\n",
    "from minisom import MiniSom\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b7473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:35:44.702343Z",
     "start_time": "2023-08-16T13:35:44.696383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up name to save files\n",
    "filedirname = '20230816_run_revision_excN2/20230816_sigma_0p5_learningrate_0p1_only3CAT_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7758062f",
   "metadata": {},
   "source": [
    "### 1.2. Load dataset in pickle & csv\n",
    "\n",
    "The data in pickle comes from zenodo: https://doi.org/10.5281/zenodo.8185883.\n",
    "\n",
    "The data in csv comes from dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14467d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:35:47.148553Z",
     "start_time": "2023-08-16T13:35:47.102877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load PCE_df_grouping, already pre-processed\n",
    "PCE_df = pd.read_csv('dataset/PCE_df_grouping.csv').drop(['Unnamed: 0'],axis=1)\n",
    "PCE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc1fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:35:48.293511Z",
     "start_time": "2023-08-16T13:35:47.864474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the mySeriesDrop that only has MPPTdata\n",
    "with open('dataset/pkl_complete/20230303_mySeriesDrop.pkl', \"rb\") as fh:\n",
    "    mySeriesDrop = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b67d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:35:48.404449Z",
     "start_time": "2023-08-16T13:35:48.363003Z"
    }
   },
   "outputs": [],
   "source": [
    "mySeriesDrop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d4b22",
   "metadata": {},
   "source": [
    "## 2. Look at the data and do further processing\n",
    "\n",
    "### 2.1. Plot the PCE_df containing calculated PCE_before (group of PCE) and PCE_delta (change in PCE at 150 hours in comparison to max. PCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef727df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:35:53.642765Z",
     "start_time": "2023-08-16T13:35:52.222804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the group into 5\n",
    "n_group = 5\n",
    "\n",
    "# Print unique values for each group\n",
    "unique_ceil = PCE_df['PCE_before_ceil_x'].unique()\n",
    "unique_median = PCE_df['PCE_before_median_x'].unique()\n",
    "unique_mean = PCE_df['PCE_before_mean_x'].unique()\n",
    "\n",
    "# Load libraries for plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Plot boxplot\n",
    "fig = px.box(PCE_df, x=\"PCE_before_x\", y=\"PCE_delta\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9cf883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:35:53.776374Z",
     "start_time": "2023-08-16T13:35:53.643738Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot violin plot\n",
    "fig = px.violin(PCE_df, x=\"PCE_before_x\", y=\"PCE_delta\", \n",
    "                box=True, points=\"all\",hover_data=PCE_df.columns)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d354ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:04.006040Z",
     "start_time": "2023-08-16T13:35:53.777338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import colorlover as cl\n",
    "from plotly.colors import n_colors\n",
    "import matplotlib\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Label for the groups\n",
    "a = ['PCE < 10.4%','PCE 10.4-14.2%','PCE 14.2-16.8%','PCE 16.8-19.2%', 'PCE > 19.2%']\n",
    "\n",
    "print('Unique ceil: ',unique_ceil)\n",
    "print('Median: ',unique_median)\n",
    "print('Mean: ',unique_mean)\n",
    "\n",
    "# Color palette for the figure to make it pretty\n",
    "colors = n_colors('rgb(8,29,88)', 'rgb(127,205,187)', n_group, colortype='rgb')\n",
    "colors_box = n_colors('rgb(2,7,22)', 'rgb(30,50,45)', n_group, colortype='rgb')\n",
    "colors_line = n_colors('rgb(0,5,15)', 'rgb(15,25,23)', n_group, colortype='rgb')\n",
    "\n",
    "# Plotting the violin and boxplot\n",
    "for (i,color,color_line) in zip(unique_ceil, colors, colors_line):\n",
    "    fig.add_trace(go.Violin(x=PCE_df['PCE_before_x'][PCE_df['PCE_before_ceil_x'] == i],\n",
    "                            y=PCE_df['PCE_delta'][PCE_df['PCE_before_ceil_x'] == i],\n",
    "                            box_visible=False,\n",
    "                            fillcolor = color,\n",
    "                            opacity = 0.4,\n",
    "                            line = dict(color=color_line),\n",
    "                            jitter=True,\n",
    "                            meanline_visible=False))\n",
    "\n",
    "for (i,color,color_line) in zip(unique_ceil, colors, colors_line):\n",
    "    fig.add_trace(go.Box(x=PCE_df['PCE_before_x'][PCE_df['PCE_before_ceil_x'] == i],\n",
    "                            y=PCE_df['PCE_delta'][PCE_df['PCE_before_ceil_x'] == i],\n",
    "                            marker_color = color,\n",
    "                            opacity = 0.55,\n",
    "                            line_color = color_line,\n",
    "                            fillcolor = color,\n",
    "                            jitter=True,\n",
    "                            boxmean=True))\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Max. PCE group (%)\",\n",
    "                  yaxis_title=\"Relative change in max. PCE (after 150 hrs.) (%)\",\n",
    "                  boxgap = 0.85,\n",
    "                  font_family='Arial',\n",
    "                  showlegend=False)\n",
    "    \n",
    "fig.show()\n",
    "\n",
    "# Save the figure \n",
    "pio.write_image(fig, filedirname+'all_data_changedegradation_4.png',\n",
    "                width=900, height=600, scale=22)\n",
    "\n",
    "pio.write_image(fig, filedirname+'all_data_changedegradation_3.png',\n",
    "                width=700, height=450, scale=25)\n",
    "\n",
    "pio.write_image(fig, filedirname+'all_data_changedegradation_5.png',\n",
    "                width=600, height=400, scale=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8c2c4",
   "metadata": {},
   "source": [
    "### 2.2. Scaling/ normalization of the MPPT data\n",
    "\n",
    "There are two types of scaling/ normalization:\n",
    "\n",
    "1. sklearn.preprocessing.MinMaxScaler -> scaling between min-max of the data (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)\n",
    "\n",
    "2. sklearn.preprocessing.MaxAbsScaler -> scaling between 0 and max of the data (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4390d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:06.441792Z",
     "start_time": "2023-08-16T13:36:06.423760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing: scaling/ normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# Function to scale, normalize and plot it\n",
    "def normalize(mySeriesDrop,normalizationMethod):\n",
    "    '''\n",
    "    A function to normalize and plot the result\n",
    "    \n",
    "    input:\n",
    "    1. mySeriesDrop (only contains MPPTdata)\n",
    "    2. normalizationMethod: a string of normalization type, 'MinMaxScaler',\n",
    "       'MaxAbsScaler'\n",
    "    \n",
    "    '''\n",
    "    mySeriesDrop_norm = mySeriesDrop.copy()\n",
    "    \n",
    "    # MinMaxScaler\n",
    "    if normalizationMethod == 'MinMaxScaler':\n",
    "        for i in range(len(mySeriesDrop_norm)):\n",
    "            scaler = MinMaxScaler()\n",
    "            mySeriesDrop_norm[i] = MinMaxScaler().fit_transform(mySeriesDrop_norm[i])\n",
    "            mySeriesDrop_norm[i]= mySeriesDrop_norm[i].reshape(len(mySeriesDrop_norm[i]))\n",
    "    \n",
    "    # MaxAbsScaler\n",
    "    elif normalizationMethod == 'MaxAbsScaler':\n",
    "        for i in range(len(mySeriesDrop_norm)):\n",
    "            scaler = MaxAbsScaler()\n",
    "            mySeriesDrop_norm[i] = MaxAbsScaler().fit_transform(mySeriesDrop_norm[i])\n",
    "            mySeriesDrop_norm[i]= mySeriesDrop_norm[i].reshape(len(mySeriesDrop_norm[i]))\n",
    "    \n",
    "    # Plot the first 100 of data\n",
    "    fig, axs = plt.subplots(10,10,figsize=(30,30), sharex=True, sharey=True)\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            if i*10+j+1>len(mySeriesDrop_norm): # pass the others that we can't fill\n",
    "                continue\n",
    "            axs[i, j].plot(mySeriesDrop_norm[i*10+j])\n",
    "\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    return mySeriesDrop_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0761d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:25.615640Z",
     "start_time": "2023-08-16T13:36:08.023755Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mySeriesDrop_maxAbs = normalize(mySeriesDrop,'MaxAbsScaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a0ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:25.631294Z",
     "start_time": "2023-08-16T13:36:25.615717Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mySeriesDrop_minMax = normalize(mySeriesDrop,'MinMaxScaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93c713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:25.677328Z",
     "start_time": "2023-08-16T13:36:25.633292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the mySeriesDrop as .pkl file (only has MPPTdata)\n",
    "# mySeriesDrop_maxAbs.to_pickle('./dataset/pkl_complete/20230116_mySeriesDropNorm.pkl')\n",
    "mySeriesDrop_maxAbs.to_pickle('./dataset/pkl_complete/20230303_mySeriesDropNorm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca938afe",
   "metadata": {},
   "source": [
    "### 2.3. Smoothing of the MPPT data\n",
    "\n",
    "Because the data is noisy, we are going to do some 'smoothing' using Savitzky-Golay filter (https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.savgol_filter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f58651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:33.165036Z",
     "start_time": "2023-08-16T13:36:33.135009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the mySeriesDrop that only has MPPTdata\n",
    "# with open('dataset/pkl_complete/20230116_mySeriesDropNorm.pkl', \"rb\") as fh:\n",
    "#     mySeriesDrop = pickle.load(fh)\n",
    "with open('dataset/pkl_complete/20230303_mySeriesDropNorm.pkl', \"rb\") as fh:\n",
    "    mySeriesDrop = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e67b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:33.599692Z",
     "start_time": "2023-08-16T13:36:33.581684Z"
    }
   },
   "outputs": [],
   "source": [
    "mySeriesDrop = mySeriesDrop_maxAbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733bf5ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:48.554461Z",
     "start_time": "2023-08-16T13:36:34.053009Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the overview of the MPPT data (the first 100 data)\n",
    "\n",
    "fig, axs = plt.subplots(10,10,figsize=(30,30),sharex=True,sharey=True)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i*10+j+1>len(mySeriesDrop): # pass the others that we can't fill\n",
    "            continue\n",
    "        axs[i, j].plot(mySeriesDrop[i*10+j])\n",
    "        \n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd596d",
   "metadata": {},
   "source": [
    "We are showing 3 different methods for smoothing:\n",
    "\n",
    "1. np.convolve (rolling average)\n",
    "\n",
    "2. scipy.signal.lfilter\n",
    "\n",
    "3. scipy.signal.savgol (savitzky-golay), which is eventually chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede21a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:48.811239Z",
     "start_time": "2023-08-16T13:36:48.556424Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert to rolling average/ np.convolve\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "curve_interest = mySeriesDrop[200]\n",
    "\n",
    "# Plotting the result\n",
    "y_smooth_3 = smooth(curve_interest,3)\n",
    "plt.figure(figsize=(4,2),dpi=300)\n",
    "plt.plot(curve_interest,'o',alpha=0.05)\n",
    "plt.plot(smooth(curve_interest,3), 'r-', lw=1)\n",
    "plt.plot(smooth(curve_interest,50), 'g-', lw=1)\n",
    "\n",
    "plt.legend(['actual data','convolve:3','convolve:50'])\n",
    "\n",
    "print(len(curve_interest), len(y_smooth_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0d123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:49.135994Z",
     "start_time": "2023-08-16T13:36:48.814208Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Smoothing using l filter\n",
    "\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "n1 = 15  # the larger n is, the smoother curve will be\n",
    "b1 = [1.0 / n1] * n1\n",
    "a1 = 1\n",
    "\n",
    "n2 = 30  # the larger n is, the smoother curve will be\n",
    "b2 = [1.0 / n2] * n2\n",
    "a2 = 1\n",
    "\n",
    "curve_interest = mySeriesDrop[200]\n",
    "\n",
    "# Plotting with l filter\n",
    "y_smooth_3 = smooth(curve_interest,3)\n",
    "plt.figure(figsize=(4,2),dpi=300)\n",
    "plt.plot(curve_interest,'o',alpha=0.05)\n",
    "plt.plot(lfilter(b1,a1,curve_interest), 'r-', lw=1)\n",
    "plt.plot(lfilter(b2,a2,curve_interest), 'g-', lw=1)\n",
    "\n",
    "plt.legend(['actual data','lfilter n:15','lfilter n:30'])\n",
    "\n",
    "print(len(curve_interest), len(lfilter(b1,a1,curve_interest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ee850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:49.431502Z",
     "start_time": "2023-08-16T13:36:49.137886Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using savitzky-golay filter\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "curve_interest = mySeriesDrop[200] #1195-1224 JSON-lea_1 sample 1 pixel 0\n",
    "\n",
    "w1 = savgol_filter(curve_interest, 71, 2)\n",
    "w2 = savgol_filter(curve_interest, 201, 2)\n",
    "\n",
    "# Plotting the figure\n",
    "plt.figure(figsize=(4,2),dpi=300)\n",
    "plt.plot(curve_interest,'o',alpha=0.05)\n",
    "plt.plot(w1, 'r-', lw=1)\n",
    "plt.plot(w2, 'g-', lw=1)\n",
    "\n",
    "print(len(curve_interest), len(w1), len(w2))\n",
    "\n",
    "plt.legend(['actual data','savgol window:71','savgol window:201'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ea1e8",
   "metadata": {},
   "source": [
    "Since Savgol with parameter=71 seems to work the best at smoothing, we are going to use that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d98e43",
   "metadata": {},
   "source": [
    "**CHECK IF SAVGOL WORKS IN ALL THE ROWS, IF THE FOLLOWING CELL CAN BE RUN WITH NO ERROR, CONTINUE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e23214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:58.197001Z",
     "start_time": "2023-08-16T13:36:49.433479Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to savgol: 71\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "n = 71\n",
    "mySeriesDrop_savgol = []\n",
    "\n",
    "# Calculating savgol series for all the rows\n",
    "for i in range(len(mySeriesDrop)):\n",
    "    print('row :',i)\n",
    "    savgol = savgol_filter(mySeriesDrop[i], n,2)\n",
    "    mySeriesDrop_savgol.append(savgol)\n",
    "\n",
    "# Trying to plot after savgol filter\n",
    "fig, axs = plt.subplots(7,7,figsize=(18,18),sharex=True)\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        if i*7+j+1>len(mySeriesDrop_savgol): # pass the others that we can't fill\n",
    "            continue\n",
    "        axs[i, j].plot(mySeriesDrop[i*7+j],'o',color='b',alpha=0.05)#.values)\n",
    "        axs[i, j].plot(mySeriesDrop_savgol[i*7+j],color='r',lw=2)#.values)\n",
    "\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53f663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:36:58.226693Z",
     "start_time": "2023-08-16T13:36:58.197974Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Save numpy array as .npy instead of .pkl\n",
    "np.save('dataset/pkl_complete/20230303_mySeriesDrop_savgol.npy',mySeriesDrop_savgol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b6846",
   "metadata": {},
   "source": [
    "## 3. SOM/ self-organizing map\n",
    "\n",
    "Read more about SOM here: https://en.wikipedia.org/wiki/Self-organizing_map.\n",
    "\n",
    "**input**: clean, pre-processed MPPT data\n",
    "\n",
    "**process**:\n",
    "\n",
    "1. cluster them using SOM, explore 3 different parameters combination to see how consistent the clustering results are\n",
    "2. plot the clusters and distribution\n",
    "3. split based on the device architecture, plot them\n",
    "4. look at both clusters and max. PCE group (see if certain clusters correlate with certain max. PCE group more)\n",
    "5. trendline of relative change -150hrs and the max. PCE group\n",
    "\n",
    "**output**: \n",
    "1. som clusters\n",
    "2. plots\n",
    "3. trendline (what is the x-intercept?)\n",
    "\n",
    "### 3.1. SOM clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8930c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:37:55.210222Z",
     "start_time": "2023-08-16T13:37:55.200198Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "\n",
    "import math\n",
    "from minisom import MiniSom\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import ImageColor\n",
    "\n",
    "# Load libraries for plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123258b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:37:55.535059Z",
     "start_time": "2023-08-16T13:37:55.519237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparing color palettes and opacity\n",
    "\n",
    "opacity = 0.5\n",
    "\n",
    "colors=[ImageColor.getcolor(px.colors.qualitative.Pastel1[0],'RGB'),\n",
    "        ImageColor.getcolor(px.colors.qualitative.Pastel1[1],'RGB'),\n",
    "        ImageColor.getcolor(px.colors.qualitative.Pastel1[2],'RGB'),\n",
    "        ImageColor.getcolor(px.colors.qualitative.Pastel1[3],'RGB')]\n",
    "\n",
    "colors_solid=[ImageColor.getcolor(px.colors.qualitative.Set1[0],'RGB'),\n",
    "              ImageColor.getcolor(px.colors.qualitative.Set1[1],'RGB'),\n",
    "              ImageColor.getcolor(px.colors.qualitative.Set1[2],'RGB'),\n",
    "              ImageColor.getcolor(px.colors.qualitative.Set1[3],'RGB')]\n",
    "\n",
    "colors_rgba=[]\n",
    "colors_solid_rgba=[]\n",
    "\n",
    "for i in range(len(colors)):\n",
    "    colors_rgba.append('rgba'+str(colors[i])[:-1]+','+str(opacity)+')')\n",
    "    \n",
    "for i in range(len(colors_solid)):\n",
    "    colors_solid_rgba.append('rgba'+str(colors_solid[i])[:-1]+','+str(opacity)+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd0edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:37:56.065090Z",
     "start_time": "2023-08-16T13:37:56.029096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot with plotly\n",
    "\n",
    "import plotly.io as pio\n",
    "import colorlover as cl\n",
    "from plotly.colors import n_colors\n",
    "import matplotlib\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Functions to plot the series\n",
    "\n",
    "# Plot using averaged center\n",
    "    \n",
    "def plot_som_series_averaged_center(som_x, som_y, win_map, name):\n",
    "    \n",
    "    fig = make_subplots(\n",
    "    rows=som_x, cols=som_y,\n",
    "    shared_xaxes=True,\n",
    "    shared_yaxes=True,\n",
    "    vertical_spacing=0.1,#0.02,#0.1,\n",
    "    )\n",
    "    \n",
    "    # Colors\n",
    "    opacity = 0.04\n",
    "\n",
    "    colors=[ImageColor.getcolor(px.colors.qualitative.Antique[4],'RGB'),\n",
    "            ImageColor.getcolor(px.colors.qualitative.Antique[9],'RGB'),\n",
    "            ImageColor.getcolor(px.colors.qualitative.Antique[6],'RGB'),\n",
    "            ImageColor.getcolor(px.colors.qualitative.Antique[8],'RGB')]\n",
    "\n",
    "    colors_solid=[ImageColor.getcolor(px.colors.qualitative.Set1[0],'RGB'),\n",
    "                  ImageColor.getcolor(px.colors.qualitative.Set1[1],'RGB'),\n",
    "                  ImageColor.getcolor(px.colors.qualitative.Set1[2],'RGB'),\n",
    "                  ImageColor.getcolor(px.colors.qualitative.Set1[3],'RGB')]\n",
    "\n",
    "    colors_rgba=[]\n",
    "    colors_solid_rgba=[]\n",
    "\n",
    "    for i in range(len(colors)):\n",
    "        colors_rgba.append('rgba'+str(colors[i])[:-1]+','+str(opacity)+')')\n",
    "\n",
    "    for i in range(len(colors_solid)):\n",
    "        colors_solid_rgba.append('rgba'+str(colors_solid[i])[:-1]+','+str(opacity)+')')\n",
    "    \n",
    "    # Color count\n",
    "    color_count = 0\n",
    "    \n",
    "    # Time\n",
    "    time = np.linspace(0,hour_limit, 900, endpoint=True)\n",
    "    \n",
    "    # Create the subplots\n",
    "    for x in range(som_x):\n",
    "        for y in range(som_y):\n",
    "            cluster = (x,y)\n",
    "            cluster_number = x*som_y+y\n",
    "            if cluster in win_map.keys():\n",
    "\n",
    "                for series in win_map[cluster]:\n",
    "                    \n",
    "                    # Cluster colors\n",
    "                    if cluster==(0,0):\n",
    "                        line_color = colors_rgba[0]\n",
    "                        solid_color = colors_solid_rgba[0]\n",
    "                    elif cluster==(0,1):\n",
    "                        line_color = colors_rgba[1]\n",
    "                        solid_color = colors_solid_rgba[1]\n",
    "                    elif cluster==(1,0):\n",
    "                        line_color = colors_rgba[2]\n",
    "                        solid_color = colors_solid_rgba[2]\n",
    "                    else:\n",
    "                        line_color = colors_rgba[3]\n",
    "                        solid_color = colors_solid_rgba[3]\n",
    "                        \n",
    "                    # Plot the traces \n",
    "                    fig.add_trace(go.Scatter(x=time, y=series, mode='lines',\n",
    "                                             name=f\"Cluster {cluster_number}\",\n",
    "                                             opacity=0.2,\n",
    "#                                              line=dict(color='darkgrey'),\n",
    "                                             line=dict(color=line_color),\n",
    "                                             showlegend=False),\n",
    "                                  row=x+1, col=y+1)\n",
    "                color_count=+1\n",
    "                \n",
    "                # Calculate the average\n",
    "                cluster_mean= np.average(np.vstack(win_map[cluster]),axis=0)\n",
    "                \n",
    "                # Plot the average\n",
    "                fig.add_trace(go.Scatter(x=time, y= cluster_mean, mode='lines',\n",
    "                                         name=f\"Cluster mean {cluster_number}\",\n",
    "                                         line_color='black',\n",
    "                                         showlegend=False),\n",
    "                              row=x+1, col=y+1)\n",
    "            \n",
    "            # Update the figure\n",
    "            fig.update_yaxes(range=[-0.1,1.1], row=x+1, col=y+1)\n",
    "            fig.update_layout(font_family='Arial')\n",
    "\n",
    "    # Save the figure\n",
    "    pio.write_image(fig, name+'averagedcenter_'+str(som_x)+'_'+str(som_y)+'.png', \n",
    "                    width=1.8*600, height=0.6*600, scale=15) # width=1*600, height=600, scale=15)\n",
    "    pio.write_image(fig, name+'averagedcenter_big_'+str(som_x)+'_'+str(som_y)+'.png',\n",
    "                    width=1.8*800, height=0.6*800, scale=15) # width=1*800, height=800, scale=15)\n",
    "    \n",
    "    # Showing the figure\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "# Plot using barycenter \n",
    "def plot_som_series_dba_center(som_x, som_y, win_map, name):\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=som_x, cols=som_y,\n",
    "        shared_xaxes=True,\n",
    "        shared_yaxes=True,\n",
    "        vertical_spacing=0.2,\n",
    "    )\n",
    "    \n",
    "    # Time\n",
    "    time = np.linspace(0,150, 900, endpoint=True)\n",
    "    \n",
    "    # Create the subplots\n",
    "    for x in range(som_x):\n",
    "        for y in range(som_y):\n",
    "            cluster = (x,y)\n",
    "            cluster_number = x*som_y+y\n",
    "            if cluster in win_map.keys():\n",
    "                for series in win_map[cluster]:    \n",
    "                    \n",
    "                    # Plot the traces\n",
    "                    fig.add_trace(go.Scatter(x=time, y=series, mode='lines',\n",
    "                                             name=f\"Cluster {cluster_number}\",\n",
    "                                             line_color='rgba(130,179,196,0.12)',\n",
    "                                             showlegend=False),\n",
    "                                  row=x+1, col=y+1)\n",
    "                \n",
    "                # Calculate the barycenter average\n",
    "                cluster_dtw = np.transpose(dtw_barycenter_averaging(np.vstack(win_map[cluster])))\n",
    "                \n",
    "                # Plot the barycenter average\n",
    "                fig.add_trace(go.Scatter(x=time, y= cluster_dtw[0], mode='lines',\n",
    "                                         name=f\"Cluster dtw {cluster_dtw}\",\n",
    "                                         line_color='rgb(57,103,119)',\n",
    "                                         showlegend=False),\n",
    "                              row=x+1, col=y+1)\n",
    "                    \n",
    "            # Update the figure\n",
    "            fig.update_yaxes(range=[-0.1,1.1], row=x+1, col=y+1)\n",
    "            fig.update_layout(font_family='Arial')\n",
    "\n",
    "    # Save the figure\n",
    "    pio.write_image(fig, name+'barryaverage.png', width=1*600, height=600, scale=15)\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb421a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:37:57.597575Z",
     "start_time": "2023-08-16T13:37:57.583608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up name, sigma, learning_rate\n",
    "sigma = 0.5\n",
    "learning_rate= 0.1\n",
    "hour_limit=150\n",
    "\n",
    "# Set the number of clusters\n",
    "som_x = 2\n",
    "som_y = 2\n",
    "cluster_count= som_x*som_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd019c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:39:41.229800Z",
     "start_time": "2023-08-16T13:37:59.743527Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset sns \n",
    "sns.reset_orig()\n",
    "\n",
    "# Calculate the SOM\n",
    "som = MiniSom(som_x, som_y,len(mySeriesDrop_savgol[0]), sigma=sigma, learning_rate = learning_rate)\n",
    "\n",
    "som.random_weights_init(mySeriesDrop_savgol)\n",
    "som.train(mySeriesDrop_savgol, 50000, verbose=True)\n",
    "\n",
    "# Plot savgol\n",
    "win_map = som.win_map(mySeriesDrop_savgol)\n",
    "\n",
    "# Returns the mapping of the winner nodes and inputs\n",
    "plot_som_series_averaged_center(som_x, som_y, win_map, filedirname)\n",
    "# plot_som_series_dba_center(som_x, som_y, win_map, filedirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bee63d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:41:38.057772Z",
     "start_time": "2023-08-16T13:41:38.044745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sorting the SOM results on win_map keys (to sort based on the shape manually)\n",
    "\n",
    "# CHANGE SEQUENCE HERE: Turn into single digit keys\n",
    "win_map[0] = win_map.pop((0,0))\n",
    "win_map[1] = win_map.pop((0,1))\n",
    "win_map[2] = win_map.pop((1,0))\n",
    "win_map[3] = win_map.pop((1,1))\n",
    "\n",
    "win_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24000f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:43:14.585267Z",
     "start_time": "2023-08-16T13:41:38.058739Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now turn back into the mapping (DON'T CHANGE ANYTHING)\n",
    "win_map[(0,0)] = win_map.pop(0)\n",
    "win_map[(0,1)] = win_map.pop(1)\n",
    "win_map[(1,0)] = win_map.pop(2)\n",
    "win_map[(1,1)] = win_map.pop(3)\n",
    "\n",
    "# Returns the mapping of the winner nodes and inputs\n",
    "plot_som_series_averaged_center(som_x, som_y, win_map, filedirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4716d2a2",
   "metadata": {},
   "source": [
    "Now, after doing the clustering, let's store the data in pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622b84f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:43:14.727235Z",
     "start_time": "2023-08-16T13:43:14.587275Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find out which data row belongs to which cluster\n",
    "som_shape = (som_x,som_y)\n",
    "winner_coordinates = np.array([som.winner(x) for x in mySeriesDrop_savgol]).T\n",
    "\n",
    "# With np.ravel_multi_index we convert the 2-dimensional\n",
    "# coordinates to a 1-dimensional index\n",
    "cluster_index_unfixed = np.ravel_multi_index(winner_coordinates, som_shape)\n",
    "\n",
    "# FIXING the labels sequence to follow the SOM results order\n",
    "cluster_index = np.empty_like(cluster_index_unfixed)\n",
    "\n",
    "for i in range(len(cluster_index_unfixed)):\n",
    "    if(cluster_index_unfixed[i]==0):\n",
    "        cluster_index[i]=(cluster_index_unfixed[i]+0) # Fix the last value based on sequence \n",
    "    elif(cluster_index_unfixed[i]==1):\n",
    "        cluster_index[i]=(cluster_index_unfixed[i]-0) # Fix the last value based on sequence \n",
    "    elif(cluster_index_unfixed[i]==2):\n",
    "        cluster_index[i]=(cluster_index_unfixed[i]+0) # Fix the last value based on sequence \n",
    "    else:\n",
    "        cluster_index[i]=(cluster_index_unfixed[i]-0) # Fix the last value based on sequence \n",
    "\n",
    "# Identify the number of clusters\n",
    "cluster_c = [len(cluster_index[cluster_index==i]) for i in np.unique(cluster_index)]\n",
    "cluster_n = [\"cluster_\"+str(i) for i in np.unique(cluster_index)]\n",
    "\n",
    "fancy_names_for_labels = [f\"{label}\" for label in cluster_index]\n",
    "# result = pd.DataFrame(zip(mySeries['Filename'],mySeries['Pixel'],\n",
    "#                           mySeries['SampleNumber'],fancy_names_for_labels),\n",
    "#                       columns=[\"Series\",'Pixel',\"SampleNumber\",\"Cluster\"]).sort_values(by=\"Cluster\") #.set_index(\"Series\")\n",
    "\n",
    "result = pd.DataFrame(zip(fancy_names_for_labels),\n",
    "                      columns=[\"Cluster\"]).sort_values(by=\"Cluster\")\n",
    "\n",
    "result['PCE_before_x'] = PCE_df['PCE_before_x']\n",
    "result['PCE_before_ceil_x'] = PCE_df['PCE_before_ceil_x']\n",
    "result['PCE_before_median_x'] = PCE_df['PCE_before_median_x']\n",
    "result['PCE_before_mean_x'] = PCE_df['PCE_before_mean_x']\n",
    "result['PCE_delta'] = PCE_df['PCE_delta']\n",
    "\n",
    "# Save result on the .csv file\n",
    "(result.sort_index()).to_csv(filedirname+'clusters.csv')\n",
    "\n",
    "result.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598fc30",
   "metadata": {},
   "source": [
    "### 3.2. General SOM cluster plots\n",
    "\n",
    "Now, let's plot some of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b204ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:46:40.576235Z",
     "start_time": "2023-08-16T13:46:39.147892Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Plot cluster distribution vertical\n",
    "fig = px.bar(x=cluster_n, y=cluster_c,labels=dict(x='Clusters',y='Count'))\n",
    "\n",
    "fig.update_layout(font_family='Arial')\n",
    "fig.update_traces(marker_color='rgba(57,103,119,0.7)')\n",
    "\n",
    "# Save the figure\n",
    "pio.write_image(fig, filedirname+'distribution_v.png',\n",
    "                width=1*400, height=400, scale=16)\n",
    "fig.show()\n",
    "\n",
    "# Plot horizontal distribution \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    y=cluster_n,\n",
    "    x=cluster_c,\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color= 'rgba(57,103,119,0.7)',\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(font_family='Arial',\n",
    "                  xaxis=dict(title='Count'),\n",
    "                  yaxis=dict(title='Cluster'))\n",
    "\n",
    "pio.write_image(fig, filedirname+'distribution_h.png', width=1*400, height=1*400, scale=16)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a1222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:46:42.030090Z",
     "start_time": "2023-08-16T13:46:40.578233Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Colormap PCE\n",
    "colormap_PCE = {1.0: \"#034e7b\",\n",
    "                2.0: \"#0570b0\",\n",
    "                3.0: \"#3690c0\",\n",
    "                4.0: \"#74a9cf\",\n",
    "                5.0: \"#a6bddb\"}\n",
    "\n",
    "# Colormap cluster\n",
    "colormap_cluster = {\"0\": px.colors.qualitative.Antique[4],\n",
    "                    \"1\": px.colors.qualitative.Antique[9],\n",
    "                    \"2\": px.colors.qualitative.Antique[6],\n",
    "                    \"3\": px.colors.qualitative.Antique[8]}\n",
    "\n",
    "# Plot histogram for PCE group distribution\n",
    "fig = px.histogram(result.sort_values(by=['Cluster','PCE_before_x']),\n",
    "                   x=\"Cluster\", color='PCE_before_x',\n",
    "                   color_discrete_map=colormap_PCE, opacity=0.75,\n",
    "#                    histnorm='percent',\n",
    "                  )\n",
    "# Update layout\n",
    "fig.update_layout(xaxis_title=\"Cluster\",\n",
    "                  legend_title = 'Max. PCE Group',\n",
    "                  yaxis_title=\"Count\",\n",
    "                  font_family='Arial',barmode='group')#,barnorm='fraction')\n",
    "\n",
    "# Save figure\n",
    "pio.write_image(fig, filedirname+'group_2.png', width=1*400, height=1*400, scale=16)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Plot histogram for cluster distribution\n",
    "fig = px.histogram(result.sort_values(by=['Cluster','PCE_before_x']),\n",
    "                   x=\"PCE_before_x\", color='Cluster',\n",
    "                   color_discrete_map=colormap_cluster, opacity=0.7,\n",
    "#                    histnorm='percent',\n",
    "                  )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(xaxis_title=\"Max. PCE Group (%)\",# xaxis=dict(range=[7,25]),\n",
    "                  yaxis_title=\"Count\", font_family='Arial',barmode='group')#,barnorm='fraction')\n",
    "\n",
    "# Save figure\n",
    "pio.write_image(fig, filedirname+'group_3.png', width=1*400, height=1*400, scale=16)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed686c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:46:43.505564Z",
     "start_time": "2023-08-16T13:46:42.130092Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Colormap PCE\n",
    "colormap_PCE = {1.0: \"#034e7b\",\n",
    "                2.0: \"#0570b0\",\n",
    "                3.0: \"#3690c0\",\n",
    "                4.0: \"#74a9cf\",\n",
    "                5.0: \"#a6bddb\"}\n",
    "\n",
    "# Colormap cluster\n",
    "colormap_cluster = {\"0\": px.colors.qualitative.Antique[4],\n",
    "                    \"1\": px.colors.qualitative.Antique[9],\n",
    "                    \"2\": px.colors.qualitative.Antique[6],\n",
    "                    \"3\": px.colors.qualitative.Antique[8]}\n",
    "\n",
    "# Plot stacked bar based on PCE group\n",
    "fig = px.histogram(result.sort_values(by=['Cluster','PCE_before_x']),\n",
    "                   x=\"Cluster\", color='PCE_before_x',\n",
    "                   color_discrete_map=colormap_PCE, opacity=0.75,\n",
    "                   histnorm='percent',\n",
    "                  )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(xaxis_title=\"Cluster\",\n",
    "                  legend_title = 'Max. PCE Group',\n",
    "                  yaxis_title=\"Count\",\n",
    "                  font_family='Arial')#,barmode='group')#,barnorm='fraction')\n",
    "\n",
    "# Save figure\n",
    "pio.write_image(fig, filedirname+'percent_2.png', width=1*400, height=1*400, scale=16)\n",
    "fig.show()\n",
    "\n",
    "# Plot stacked bar based on cluster\n",
    "fig = px.histogram(result.sort_values(by=['Cluster','PCE_before_x']),\n",
    "                   x=\"PCE_before_x\", color='Cluster',\n",
    "                   color_discrete_map=colormap_cluster, opacity=0.75,\n",
    "                   histnorm='percent',\n",
    "                  )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(xaxis_title=\"Max. PCE Group\",#xaxis=dict(range=[7,26]),\n",
    "                  yaxis_title=\"Count\", font_family='Arial',bargap=0.1)#,barmode='group')#,barnorm='fraction')\n",
    "\n",
    "# Save figure\n",
    "pio.write_image(fig, filedirname+'percent_3.png', width=1*400, height=1*400, scale=16)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ce017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:46:44.838860Z",
     "start_time": "2023-08-16T13:46:43.507565Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Colormap PCE\n",
    "colormap_PCE = {1.0: \"#034e7b\",\n",
    "                2.0: \"#0570b0\",\n",
    "                3.0: \"#3690c0\",\n",
    "                4.0: \"#74a9cf\",\n",
    "                5.0: \"#a6bddb\"}\n",
    "\n",
    "# Colormap cluster\n",
    "colormap_cluster = {\"0\": px.colors.qualitative.Antique[4],\n",
    "                    \"1\": px.colors.qualitative.Antique[9],\n",
    "                    \"2\": px.colors.qualitative.Antique[6],\n",
    "                    \"3\": px.colors.qualitative.Antique[8]}\n",
    "\n",
    "# Plot normalized bar based on PCE group\n",
    "fig = px.histogram(result.sort_values(by=['Cluster','PCE_before_x']),\n",
    "                   x=\"Cluster\", color='PCE_before_x',\n",
    "                   color_discrete_map=colormap_PCE, opacity=0.75,\n",
    "#                    histnorm='percent',\n",
    "                  )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(xaxis_title=\"Cluster\",\n",
    "                  legend_title = 'Max. PCE Group',\n",
    "                  yaxis_title=\"Count\",\n",
    "                  font_family='Arial',barnorm='fraction')\n",
    "\n",
    "# Save figure\n",
    "pio.write_image(fig, filedirname+'fraction_2.png', width=1*400, height=1*400, scale=16)\n",
    "fig.show()\n",
    "\n",
    "# Plot normalized bar based on cluster\n",
    "fig = px.histogram(result.sort_values(by=['Cluster','PCE_before_x']),\n",
    "                   x=\"PCE_before_x\", color='Cluster',\n",
    "                   color_discrete_map=colormap_cluster, opacity=0.75,\n",
    "#                    histnorm='percent',\n",
    "                  )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(xaxis_title=\"Max. PCE Group\",#xaxis=dict(range=[9,26]),\n",
    "                  yaxis_title=\"Count\", font_family='Arial',barnorm='fraction',\n",
    "                  bargap=0.1)\n",
    "\n",
    "# Save figure\n",
    "pio.write_image(fig, filedirname+'fraction_3.png', width=1*400, height=1*400, scale=16)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b380b1",
   "metadata": {},
   "source": [
    "### 3.3. Looking at both clusters and max. PCE group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301b28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:01:41.761986Z",
     "start_time": "2023-08-16T14:01:41.730031Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load data for the clusters\n",
    "cluster_PCE = pd.read_csv(filedirname+'clusters.csv').drop(['Unnamed: 0'],axis=1)\n",
    "cluster_PCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e89ace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:01:42.346779Z",
     "start_time": "2023-08-16T14:01:42.322689Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Cluster list:')\n",
    "cluster_PCE['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de208c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:01:43.244405Z",
     "start_time": "2023-08-16T14:01:43.212373Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add cluster data to the PCE_df\n",
    "PCE_df_sorted = ((PCE_df).sort_index()).reset_index(drop=True)\n",
    "PCE_df_sorted['Cluster'] = cluster_PCE['Cluster']\n",
    "PCE_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d4a88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:02:46.753685Z",
     "start_time": "2023-08-16T14:02:41.622622Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Separate for different cluster\n",
    "\n",
    "import plotly.io as pio\n",
    "import colorlover as cl\n",
    "from plotly.colors import n_colors\n",
    "import matplotlib\n",
    "import random\n",
    "\n",
    "# Find unique values\n",
    "unique_x = PCE_df_sorted['PCE_before_x'].unique()\n",
    "\n",
    "# Colors_scatter\n",
    "colors_scatter=[ImageColor.getcolor(px.colors.qualitative.Antique[4],'RGB'),\n",
    "                ImageColor.getcolor(px.colors.qualitative.Antique[9],'RGB'),\n",
    "                ImageColor.getcolor(px.colors.qualitative.Antique[6],'RGB'),\n",
    "                ImageColor.getcolor(px.colors.qualitative.Antique[8],'RGB')]\n",
    "\n",
    "# Plot for each cluster\n",
    "for cluster in range(4): # Number of clusters: 4\n",
    "    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    colors = n_colors('rgb(8,29,88)', 'rgb(127,205,187)', 6, colortype='rgb')\n",
    "    colors_box = n_colors('rgb(2,7,22)', 'rgb(30,50,45)', 6, colortype='rgb')\n",
    "    colors_line = n_colors('rgb(0,5,15)', 'rgb(15,25,23)', 6, colortype='rgb')\n",
    "\n",
    "    # Plot the violin plot for specific cluster\n",
    "    for (i,color,color_line) in zip(unique_x, colors, colors_line):\n",
    "        fig.add_trace(go.Violin(x=(PCE_df['PCE_before_x'][PCE_df['PCE_before_x'] == i])+0,\n",
    "                                y=PCE_df_sorted['PCE_delta'][(PCE_df_sorted['PCE_before_x'] == i) & (PCE_df_sorted['Cluster']== cluster)],\n",
    "                                box_visible=False, \n",
    "                                fillcolor = color,\n",
    "                                opacity = 0.4,\n",
    "                                line = dict(color=color_line),\n",
    "                                jitter=True,\n",
    "                                meanline_visible=True\n",
    "                               )\n",
    "                     )\n",
    "    \n",
    "    # Colors scatter    \n",
    "    if cluster == 0:\n",
    "        color_scatter = px.colors.qualitative.Antique[4]#'black'#colors_scatter[0]\n",
    "    elif cluster == 1:\n",
    "        color_scatter = px.colors.qualitative.Antique[9]#'blue'#colors_scatter[1]\n",
    "    elif cluster ==2:\n",
    "        color_scatter = px.colors.qualitative.Antique[6]#'red'#colors_scatter[2]\n",
    "    else:\n",
    "        color_scatter = px.colors.qualitative.Antique[8]#'green'#colors_scatter[3]\n",
    "    \n",
    "    # Plot the scattered data points\n",
    "    for (i) in zip(unique_x):\n",
    "        x = cluster_PCE['PCE_before_x'][(cluster_PCE['PCE_before_x'] == i) & (cluster_PCE['Cluster'] == cluster)]\n",
    "        fig.add_trace(go.Scatter(x= x + 0.65*np.random.rand(len(x))-0.325, #-0.5 to center it at 0\n",
    "                                 y=PCE_df_sorted['PCE_delta'][(PCE_df_sorted['PCE_before_x'] == i) & (PCE_df_sorted['Cluster']== cluster)],\n",
    "                                 mode='markers',\n",
    "                                 marker_color=color_scatter,\n",
    "                                 marker_size=6,\n",
    "                                 opacity = 0.7,\n",
    "                                )\n",
    "                     )\n",
    "\n",
    "    # Update properties of the figure\n",
    "    fig.update_traces(marker={'size': 4})\n",
    "    \n",
    "    fig.update_layout(xaxis_title=\"Maximum PCE group (%)\",\n",
    "                      yaxis_title=\"Relative change in max. PCE (after 150 hrs.) (%)\",\n",
    "                      boxgap = 0.85,\n",
    "                      font_family='Arial',\n",
    "                      showlegend=False)\n",
    "    fig.update_yaxes(range=[-20,120],showgrid=True)\n",
    "    fig.update_xaxes(showgrid=False,showticklabels=False)\n",
    "    fig.update_layout(hovermode=\"y unified\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # Save a figure\n",
    "    pio.write_image(fig, filedirname+'group_violin_cluster_'+str(cluster)+'_2.png',\n",
    "                    width=425, height=400, scale=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477ce1b",
   "metadata": {},
   "source": [
    "### 3.4. Plot the trendline of the mean and interquartile\n",
    "\n",
    "This will give us some ideas what is the maximum, feasible PCE with 0% relative change in max. PCE after 150 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb395fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:02:49.251074Z",
     "start_time": "2023-08-16T14:02:49.171628Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import colorlover as cl\n",
    "from plotly.colors import n_colors\n",
    "import matplotlib\n",
    "\n",
    "##### CALCULATION FOR THE Y-AXIS, THE RELATIVE CHANGE IN MAX.PCE\n",
    "\n",
    "PCE_df_sorted_upto20 = PCE_df_sorted\n",
    "\n",
    "# Add the PCE_before_median_x\n",
    "PCE_df_sorted_upto20['PCE_before_x'] = PCE_df_sorted['PCE_before_x']\n",
    "PCE_df_sorted_upto20['PCE_before_median_x'] = PCE_df_sorted['PCE_before_median_x']\n",
    "PCE_df_sorted_upto20['PCE_before_mean_x'] = PCE_df_sorted['PCE_before_median_x']\n",
    "\n",
    "# Add the PCE_before_mean_x\n",
    "PCE_df_sorted_upto20['PCE_before_mean_x'].loc[PCE_df_sorted['PCE_before_x'] == 1] = PCE_df_sorted['PCE_before'].loc[PCE_df_sorted['PCE_before_x'] == 1].mean()\n",
    "PCE_df_sorted_upto20['PCE_before_mean_x'].loc[PCE_df_sorted['PCE_before_x'] == 2] = PCE_df_sorted['PCE_before'].loc[PCE_df_sorted['PCE_before_x'] == 2].mean()\n",
    "PCE_df_sorted_upto20['PCE_before_mean_x'].loc[PCE_df_sorted['PCE_before_x'] == 3] = PCE_df_sorted['PCE_before'].loc[PCE_df_sorted['PCE_before_x'] == 3].mean()\n",
    "PCE_df_sorted_upto20['PCE_before_mean_x'].loc[PCE_df_sorted['PCE_before_x'] == 4] = PCE_df_sorted['PCE_before'].loc[PCE_df_sorted['PCE_before_x'] == 4].mean()\n",
    "PCE_df_sorted_upto20['PCE_before_mean_x'].loc[PCE_df_sorted['PCE_before_x'] == 5] = PCE_df_sorted['PCE_before'].loc[PCE_df_sorted['PCE_before_x'] == 5].mean()\n",
    "\n",
    "# Extract median\n",
    "PCE_delta_median = (PCE_df_sorted_upto20.groupby('PCE_before_x')['PCE_delta'].median()).to_frame()\n",
    "PCE_delta_median = PCE_delta_median.rename_axis('PCE_before_x').reset_index()\n",
    "PCE_delta_median.rename(columns={'PCE_delta':'PCE_delta_median'},inplace=True)\n",
    "\n",
    "# Extract mean\n",
    "PCE_delta_mean = (PCE_df_sorted_upto20.groupby('PCE_before_x')['PCE_delta'].mean()).to_frame()\n",
    "PCE_delta_mean = PCE_delta_mean.rename_axis('PCE_before_x').reset_index()\n",
    "PCE_delta_mean.rename(columns={'PCE_delta':'PCE_delta_mean'},inplace=True)\n",
    "\n",
    "# Extract 25th and 75th percentile\n",
    "PCE_delta_quartile_1 = PCE_df_sorted_upto20.groupby('PCE_before_x')['PCE_delta'].quantile(0.25).to_frame()\n",
    "PCE_delta_quartile_3 = PCE_df_sorted_upto20.groupby('PCE_before_x')['PCE_delta'].quantile(0.75).to_frame()\n",
    "\n",
    "PCE_delta_quartile_1 = PCE_delta_quartile_1.rename_axis('PCE_before_x').reset_index()\n",
    "PCE_delta_quartile_3 = PCE_delta_quartile_3.rename_axis('PCE_before_x').reset_index()\n",
    "\n",
    "PCE_delta_quartile_1.rename(columns={'PCE_delta':'PCE_delta_25th'},inplace=True)\n",
    "PCE_delta_quartile_3.rename(columns={'PCE_delta':'PCE_delta_75th'},inplace=True)\n",
    "\n",
    "\n",
    "##### CALCULATION FOR THE X-AXIS, THE PCE_before_mean, PCE_before_median, PCE_before_25th, PCE_before_75th\n",
    "# Extract median x-axis\n",
    "PCE_before_median = (PCE_df_sorted_upto20.groupby('PCE_before_x')['PCE_before'].median()).to_frame()\n",
    "PCE_before_median = PCE_before_median.rename_axis('PCE_before_x').reset_index()\n",
    "PCE_before_median.rename(columns={'PCE_before':'PCE_before_median'},inplace=True)\n",
    "\n",
    "# Extract mean x-axis\n",
    "PCE_before_mean = (PCE_df_sorted_upto20.groupby('PCE_before_x')['PCE_before'].mean()).to_frame()\n",
    "PCE_before_mean = PCE_before_mean.rename_axis('PCE_before_x').reset_index()\n",
    "PCE_before_mean.rename(columns={'PCE_before':'PCE_before_mean'},inplace=True)\n",
    "\n",
    "# Extract 25th and 75th percentile\n",
    "PCE_before_quartile_1 = PCE_df_sorted_upto20.groupby('PCE_before_x')['PCE_before'].quantile(0.25).to_frame()\n",
    "PCE_before_quartile_3 = PCE_df_sorted_upto20.groupby('PCE_before_x')['PCE_before'].quantile(0.75).to_frame()\n",
    "\n",
    "PCE_before_quartile_1 = PCE_before_quartile_1.rename_axis('PCE_before_x').reset_index()\n",
    "PCE_before_quartile_3 = PCE_before_quartile_3.rename_axis('PCE_before_x').reset_index()\n",
    "\n",
    "PCE_before_quartile_1.rename(columns={'PCE_before':'PCE_before_25th'},inplace=True)\n",
    "PCE_before_quartile_3.rename(columns={'PCE_before':'PCE_before_75th'},inplace=True)\n",
    "\n",
    "##### Merge dataframe\n",
    "PCE_delta_quartiles = pd.concat([PCE_delta_median,\n",
    "                                 PCE_delta_mean.drop(columns=['PCE_before_x']),\n",
    "                                 PCE_delta_quartile_1.drop(columns=['PCE_before_x']),\n",
    "                                 PCE_delta_quartile_3.drop(columns=['PCE_before_x']),\n",
    "                                 PCE_before_median.drop(columns=['PCE_before_x']),\n",
    "                                 PCE_before_mean.drop(columns=['PCE_before_x']),\n",
    "                                 PCE_before_quartile_1.drop(columns=['PCE_before_x']),\n",
    "                                 PCE_before_quartile_3.drop(columns=['PCE_before_x'])],\n",
    "                                axis=1)\n",
    "\n",
    "# Save PCE_delta_quartiles\n",
    "PCE_delta_quartiles.to_csv(filedirname+'PCE_delta_quartiles_inc24.csv')\n",
    "\n",
    "PCE_delta_quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71374b6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:02:53.746802Z",
     "start_time": "2023-08-16T14:02:52.631560Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "# from sklearn.datasets import make_regression\n",
    "\n",
    "# Doing linear regression on MEDIAN\n",
    "print('For MEDIAN:')\n",
    "X = (PCE_delta_quartiles['PCE_before_median'].to_numpy()).reshape(-1,1)\n",
    "y = (PCE_delta_quartiles['PCE_delta_median'].to_numpy()).reshape(-1,1)\n",
    "\n",
    "# Fitting \n",
    "model= LinearRegression().fit(X,y)\n",
    "model_2 = sm.OLS(y,X).fit()\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Fitting stretched\n",
    "X_stretch = np.array([0,35]).reshape(-1,1)\n",
    "y_hat_stretch = model.predict(X_stretch)\n",
    "\n",
    "MSE=mean_squared_error(y,y_hat)\n",
    "MAE=median_absolute_error(y,y_hat)\n",
    "\n",
    "print('MSE: ',MSE)\n",
    "print('MAE: ',MAE)\n",
    "print('Model coefficients: ',model.coef_)\n",
    "print('y-intercept: ',model.intercept_)\n",
    "print('x-intercept: ',-model.intercept_/model.coef_)\n",
    "\n",
    "# Prediction\n",
    "combined_array = np.column_stack((X,y_hat))\n",
    "prediction=pd.DataFrame(combined_array,columns=['X','y_hat'])\n",
    "\n",
    "combined_array_stretch = np.column_stack((X_stretch,y_hat_stretch))\n",
    "prediction_stretch = pd.DataFrame(combined_array_stretch,\n",
    "                                  columns=['X','y_hat'])\n",
    "\n",
    "MAE_np = MAE*np.ones(len(combined_array))\n",
    "MSE_np = MSE*np.ones(len(combined_array))\n",
    "\n",
    "# Plot figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot the regression line\n",
    "fig.add_trace(go.Scatter(x=prediction_stretch['X'],y=prediction_stretch['y_hat'],\n",
    "                         mode='lines', name='Regression',\n",
    "                         line=dict(dash='dash',color='rgb(116,169,207)')))\n",
    "\n",
    "# Plot the scatter median line\n",
    "fig.add_trace(go.Scatter(x=PCE_delta_quartiles['PCE_before_median'],\n",
    "                         y=PCE_delta_quartiles['PCE_delta_median'],\n",
    "                         error_y=dict(type='data', symmetric=False,\n",
    "                                      array=PCE_delta_quartiles['PCE_delta_75th']-PCE_delta_quartiles['PCE_delta_median'],\n",
    "                                      arrayminus=PCE_delta_quartiles['PCE_delta_median']-PCE_delta_quartiles['PCE_delta_25th']),\n",
    "                         error_x=dict(type='data', symmetric=False,\n",
    "                                      array=PCE_delta_quartiles['PCE_before_75th']-PCE_delta_quartiles['PCE_before_median'],\n",
    "                                      arrayminus=PCE_delta_quartiles['PCE_before_median']-PCE_delta_quartiles['PCE_before_25th']),\n",
    "                         mode='markers',name='Median',\n",
    "                         line=dict(color='rgb(5,112,176)')))\n",
    "\n",
    "# Update figure properties\n",
    "fig.update_layout(xaxis_title=\"Maximum PCE group (%)\",\n",
    "                  yaxis_title=\"Relative change in max. PCE (after 150 hrs.) (%)\",\n",
    "                  font_family='Arial',\n",
    "                  showlegend=True)\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save a figure of 300dpi\n",
    "# pio.write_image(fig, filedirname+'median_PCE_delta_fit_inc24.png',\n",
    "#                 width=0.7*800, height=0.7*600, scale=12)\n",
    "\n",
    "pio.write_image(fig, filedirname+'median_PCE_delta_fit_inc24_stretched.png',\n",
    "                width=0.7*800, height=0.7*600, scale=12)\n",
    "\n",
    "# Model OLS summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4e068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:02:55.777060Z",
     "start_time": "2023-08-16T14:02:55.212563Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "# from sklearn.datasets import make_regression\n",
    "\n",
    "# Doing linear regression on MEDIAN\n",
    "print('For MEDIAN:')\n",
    "X = (PCE_delta_quartiles['PCE_before_median'].to_numpy()).reshape(-1,1)\n",
    "y = (PCE_delta_quartiles['PCE_delta_median'].to_numpy()).reshape(-1,1)\n",
    "\n",
    "# Fitting \n",
    "model= LinearRegression().fit(X,y)\n",
    "model_2 = sm.OLS(y,X).fit()\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Fitting stretched\n",
    "X_stretch = np.array([0,35]).reshape(-1,1)\n",
    "y_hat_stretch = model.predict(X_stretch)\n",
    "\n",
    "MSE=mean_squared_error(y,y_hat)\n",
    "MAE=median_absolute_error(y,y_hat)\n",
    "\n",
    "print('MSE: ',MSE)\n",
    "print('MAE: ',MAE)\n",
    "print('Model coefficients: ',model.coef_)\n",
    "print('y-intercept: ',model.intercept_)\n",
    "print('x-intercept: ',-model.intercept_/model.coef_)\n",
    "\n",
    "# Prediction\n",
    "combined_array = np.column_stack((X,y_hat))\n",
    "prediction=pd.DataFrame(combined_array,columns=['X','y_hat'])\n",
    "\n",
    "combined_array_stretch = np.column_stack((X_stretch,y_hat_stretch))\n",
    "prediction_stretch = pd.DataFrame(combined_array_stretch,\n",
    "                                  columns=['X','y_hat'])\n",
    "\n",
    "MAE_np = MAE*np.ones(len(combined_array))\n",
    "MSE_np = MSE*np.ones(len(combined_array))\n",
    "\n",
    "# Plot figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot the regression line\n",
    "fig.add_trace(go.Scatter(x=prediction['X'],y=prediction['y_hat'],\n",
    "                         mode='lines', name='Regression',\n",
    "                         line=dict(dash='dash',color='rgb(116,169,207)')))\n",
    "\n",
    "# Plot the scatter median line\n",
    "fig.add_trace(go.Scatter(x=PCE_delta_quartiles['PCE_before_median'],\n",
    "                         y=PCE_delta_quartiles['PCE_delta_median'],\n",
    "                         error_y=dict(type='data', symmetric=False,\n",
    "                                      array=PCE_delta_quartiles['PCE_delta_75th']-PCE_delta_quartiles['PCE_delta_median'],\n",
    "                                      arrayminus=PCE_delta_quartiles['PCE_delta_median']-PCE_delta_quartiles['PCE_delta_25th']),\n",
    "                         error_x=dict(type='data', symmetric=False,\n",
    "                                      array=PCE_delta_quartiles['PCE_before_75th']-PCE_delta_quartiles['PCE_before_median'],\n",
    "                                      arrayminus=PCE_delta_quartiles['PCE_before_median']-PCE_delta_quartiles['PCE_before_25th']),\n",
    "                         mode='markers',name='Median',\n",
    "                         line=dict(color='rgb(5,112,176)')))\n",
    "\n",
    "# Update figure properties\n",
    "fig.update_layout(xaxis_title=\"Maximum PCE group (%)\",\n",
    "                  yaxis_title=\"Relative change in max. PCE (after 150 hrs.) (%)\",\n",
    "                  font_family='Arial',\n",
    "                  showlegend=True)\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save a figure of 300dpi\n",
    "# pio.write_image(fig, filedirname+'median_PCE_delta_fit_inc24.png',\n",
    "#                 width=0.7*800, height=0.7*600, scale=12)\n",
    "\n",
    "pio.write_image(fig, filedirname+'median_PCE_delta_fit_inc24.png',\n",
    "                width=0.7*800, height=0.7*600, scale=12)\n",
    "\n",
    "# Model OLS summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b23aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:02:56.702479Z",
     "start_time": "2023-08-16T14:02:56.128520Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "# from sklearn.datasets import make_regression\n",
    "\n",
    "# Doing linear regression on MEAN\n",
    "print('For MEAN:')\n",
    "X = (PCE_delta_quartiles['PCE_before_mean'].to_numpy()).reshape(-1,1)\n",
    "y = (PCE_delta_quartiles['PCE_delta_mean'].to_numpy()).reshape(-1,1)\n",
    "\n",
    "# Fitting \n",
    "model= LinearRegression().fit(X,y)\n",
    "model_2 = sm.OLS(y,X).fit()\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Fitting stretched\n",
    "X_stretch = np.array([0,35]).reshape(-1,1)\n",
    "y_hat_stretch = model.predict(X_stretch)\n",
    "\n",
    "MSE=mean_squared_error(y,y_hat)\n",
    "MAE=median_absolute_error(y,y_hat)\n",
    "\n",
    "print('MSE: ',MSE)\n",
    "print('MAE: ',MAE)\n",
    "print('Model coefficients: ',model.coef_)\n",
    "print('y-intercept: ',model.intercept_)\n",
    "print('x-intercept: ',-model.intercept_/model.coef_)\n",
    "\n",
    "# Prediction\n",
    "combined_array = np.column_stack((X,y_hat))\n",
    "prediction=pd.DataFrame(combined_array,columns=['X','y_hat'])\n",
    "\n",
    "combined_array_stretch = np.column_stack((X_stretch,y_hat_stretch))\n",
    "prediction_stretch = pd.DataFrame(combined_array_stretch,\n",
    "                                  columns=['X','y_hat'])\n",
    "\n",
    "MAE_np = MAE*np.ones(len(combined_array))\n",
    "MSE_np = MSE*np.ones(len(combined_array))\n",
    "\n",
    "# Plot figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot the regression line\n",
    "fig.add_trace(go.Scatter(x=prediction_stretch['X'],y=prediction_stretch['y_hat'],\n",
    "                         mode='lines', name='Regression',\n",
    "                         line=dict(dash='dash',color='rgb(116,169,207)')))\n",
    "\n",
    "# Plot the scatter median line\n",
    "fig.add_trace(go.Scatter(x=PCE_delta_quartiles['PCE_before_mean'],\n",
    "                         y=PCE_delta_quartiles['PCE_delta_mean'],\n",
    "                         error_y=dict(type='data', symmetric=False,\n",
    "                                      array=PCE_delta_quartiles['PCE_delta_75th']-PCE_delta_quartiles['PCE_delta_mean'],\n",
    "                                      arrayminus=PCE_delta_quartiles['PCE_delta_mean']-PCE_delta_quartiles['PCE_delta_25th']),\n",
    "                         error_x=dict(type='data', symmetric=False,\n",
    "                                      array=PCE_delta_quartiles['PCE_before_75th']-PCE_delta_quartiles['PCE_before_mean'],\n",
    "                                      arrayminus=PCE_delta_quartiles['PCE_before_mean']-PCE_delta_quartiles['PCE_before_25th']),\n",
    "                         mode='markers',name='Mean',\n",
    "                         line=dict(color='rgb(5,112,176)')))\n",
    "\n",
    "# Update figure properties\n",
    "fig.update_layout(xaxis_title=\"Maximum PCE group (%)\",\n",
    "                  yaxis_title=\"Relative change in max. PCE (after 150 hrs.) (%)\",\n",
    "                  font_family='Arial',\n",
    "                  showlegend=True)\n",
    "    \n",
    "fig.show()\n",
    "\n",
    "# Save a figure of 300dpi\n",
    "pio.write_image(fig, filedirname+'mean_PCE_delta_fit_inc24_stretched.png',\n",
    "                width=0.7*800, height=0.7*600, scale=12)\n",
    "\n",
    "# Model OLS summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693632a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:02:57.345997Z",
     "start_time": "2023-08-16T14:02:56.790034Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "# from sklearn.datasets import make_regression\n",
    "\n",
    "# Doing linear regression on MEAN\n",
    "print('For MEAN:')\n",
    "X = (PCE_delta_quartiles['PCE_before_mean'].to_numpy()).reshape(-1,1)\n",
    "y = (PCE_delta_quartiles['PCE_delta_mean'].to_numpy()).reshape(-1,1)\n",
    "\n",
    "# Fitting \n",
    "model= LinearRegression().fit(X,y)\n",
    "model_2 = sm.OLS(y,X).fit()\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Fitting stretched\n",
    "X_stretch = np.array([0,35]).reshape(-1,1)\n",
    "y_hat_stretch = model.predict(X_stretch)\n",
    "\n",
    "MSE=mean_squared_error(y,y_hat)\n",
    "MAE=median_absolute_error(y,y_hat)\n",
    "\n",
    "print('MSE: ',MSE)\n",
    "print('MAE: ',MAE)\n",
    "print('Model coefficients: ',model.coef_)\n",
    "print('y-intercept: ',model.intercept_)\n",
    "print('x-intercept: ',-model.intercept_/model.coef_)\n",
    "\n",
    "# Prediction\n",
    "combined_array = np.column_stack((X,y_hat))\n",
    "prediction=pd.DataFrame(combined_array,columns=['X','y_hat'])\n",
    "\n",
    "combined_array_stretch = np.column_stack((X_stretch,y_hat_stretch))\n",
    "prediction_stretch = pd.DataFrame(combined_array_stretch,\n",
    "                                  columns=['X','y_hat'])\n",
    "\n",
    "MAE_np = MAE*np.ones(len(combined_array))\n",
    "MSE_np = MSE*np.ones(len(combined_array))\n",
    "\n",
    "# Plot figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot the regression line\n",
    "fig.add_trace(go.Scatter(x=prediction['X'],y=prediction['y_hat'],\n",
    "                         mode='lines', name='Regression',\n",
    "                         line=dict(dash='dash',color='rgb(116,169,207)')))\n",
    "\n",
    "# Plot the scatter median line\n",
    "fig.add_trace(go.Scatter(x=PCE_delta_quartiles['PCE_before_mean'],\n",
    "                         y=PCE_delta_quartiles['PCE_delta_mean'],\n",
    "                         error_y=dict(type='data', symmetric=False,\n",
    "                                      array=PCE_delta_quartiles['PCE_delta_75th']-PCE_delta_quartiles['PCE_delta_mean'],\n",
    "                                      arrayminus=PCE_delta_quartiles['PCE_delta_mean']-PCE_delta_quartiles['PCE_delta_25th']),\n",
    "                         error_x=dict(type='data', symmetric=False,\n",
    "                                      array=PCE_delta_quartiles['PCE_before_75th']-PCE_delta_quartiles['PCE_before_mean'],\n",
    "                                      arrayminus=PCE_delta_quartiles['PCE_before_mean']-PCE_delta_quartiles['PCE_before_25th']),\n",
    "                         mode='markers',name='Mean',\n",
    "                         line=dict(color='rgb(5,112,176)')))\n",
    "\n",
    "# Update figure properties\n",
    "fig.update_layout(xaxis_title=\"Maximum PCE group (%)\",\n",
    "                  yaxis_title=\"Relative change in max. PCE (after 150 hrs.) (%)\",\n",
    "                  font_family='Arial',\n",
    "                  showlegend=True)\n",
    "    \n",
    "fig.show()\n",
    "\n",
    "# Save a figure of 300dpi\n",
    "pio.write_image(fig, filedirname+'mean_PCE_delta_fit_inc24.png',\n",
    "                width=0.7*800, height=0.7*600, scale=12)\n",
    "\n",
    "# Model OLS summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7191a",
   "metadata": {},
   "source": [
    "## 4. Time series k-means clustering\n",
    "\n",
    "Read more about k-means clustering here: https://en.wikipedia.org/wiki/K-means_clustering.\n",
    "\n",
    "**input**: clean, pre-processed mySeriesDrop_savgol from above\n",
    "\n",
    "**process**:\n",
    "\n",
    "1. do k-means clustering with the same number of clusters as som\n",
    "2. visualization using PCA: k-means, affinity propagation, and dbscan (this one is too long)\n",
    "3. visualization using t-SNE: k-means, affinity propagation\n",
    "4. plot the cluster distribution\n",
    "5. plot elbow method and silhouette method for optimum number of clusters\n",
    "\n",
    "**output**: \n",
    "1. optimum number for clustering\n",
    "2. 2d map of the data points, and their clusters\n",
    "\n",
    "### 4.1. Direct k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mySeriesDrop_savgol, uncomment to check:\n",
    "# mySeriesDrop_savgol\n",
    "\n",
    "# Load mySeriesDrop_savgol\n",
    "mySeriesDrop_savgol=np.load('dataset/pkl_complete/20230303_mySeriesDrop_savgol.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075b7af",
   "metadata": {},
   "source": [
    "Beware, the following cell takes a really long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03f450",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:19:29.871106Z",
     "start_time": "2022-12-15T11:11:56.997677Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Using the same number of clusters as the SOM\n",
    "som_x = 2\n",
    "som_y = 2\n",
    "cluster_count= som_x*som_y\n",
    "\n",
    "# K-means clustering\n",
    "km = TimeSeriesKMeans(n_clusters=cluster_count, metric=\"dtw\")\n",
    "labels = km.fit_predict(mySeriesDrop_savgol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcd673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving models as pickle\n",
    "km.to_pickle(filedirname+'TimeSeriesKMeans_4clusters_2.pkl')\n",
    "\n",
    "# Save numpy array as .npy instead of .pkl\n",
    "np.save(filedirname+'TimeSeriesKMeans_labels_dtw_4clusters_2.npy',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e5af9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:38:40.353722Z",
     "start_time": "2022-12-15T12:38:40.337722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up name to save files\n",
    "\n",
    "# filedirname = '20230116_run/sigma_0p5_learningrate_0p1/20230116_sigma_0p5_learningrate_0p1_'\n",
    "\n",
    "# If not, let's load labels and km\n",
    "with open(filedirname+'TimeSeriesKMeans_4clusters_2.pkl', \"rb\") as fh:\n",
    "    km = pickle.load(fh)\n",
    "labels=np.load(filedirname+'TimeSeriesKMeans_labels_dtw_4clusters_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79cdd71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:44:07.785779Z",
     "start_time": "2022-12-15T12:44:07.766777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixing the labels sequence to follow the SOM results order\n",
    "\n",
    "labels_fixed = np.empty_like(labels)\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i]==0):\n",
    "        labels_fixed[i]=(labels[i]+1) # Fix based on the sequence\n",
    "    elif(labels[i]==1):\n",
    "        labels_fixed[i]=(labels[i]+1) # Fix based on the sequence\n",
    "    elif(labels[i]==2):\n",
    "        labels_fixed[i]=(labels[i]+1) # Fix based on the sequence\n",
    "    else:\n",
    "        labels_fixed[i]=(labels[i]-3) # Fix based on the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5cfc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:44:54.394197Z",
     "start_time": "2022-12-15T12:44:12.292878Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import colorlover as cl\n",
    "from plotly.colors import n_colors\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Now, let's plot the results (based on the savgol/ smoothed )\n",
    "plot_count = som_x\n",
    "\n",
    "# Time\n",
    "time = np.linspace(0,150, 900, endpoint=True)\n",
    "\n",
    "# Plot figure\n",
    "fig = make_subplots(\n",
    "    rows=som_x, cols=som_y,\n",
    "    shared_xaxes=True,\n",
    "    shared_yaxes=True,\n",
    "    vertical_spacing=0.1,\n",
    "    )\n",
    "\n",
    "row_i = 0\n",
    "column_j = 0\n",
    "\n",
    "# Colors\n",
    "opacity = 0.04\n",
    "\n",
    "colors=[ImageColor.getcolor(px.colors.qualitative.Antique[4],'RGB'),\n",
    "        ImageColor.getcolor(px.colors.qualitative.Antique[9],'RGB'),\n",
    "        ImageColor.getcolor(px.colors.qualitative.Antique[6],'RGB'),\n",
    "        ImageColor.getcolor(px.colors.qualitative.Antique[8],'RGB')]\n",
    "\n",
    "colors_solid=[ImageColor.getcolor(px.colors.qualitative.Set1[0],'RGB'),\n",
    "              ImageColor.getcolor(px.colors.qualitative.Set1[1],'RGB'),\n",
    "              ImageColor.getcolor(px.colors.qualitative.Set1[2],'RGB'),\n",
    "              ImageColor.getcolor(px.colors.qualitative.Set1[3],'RGB')]\n",
    "\n",
    "colors_rgba=[]\n",
    "colors_solid_rgba=[]\n",
    "\n",
    "\n",
    "for i in range(len(colors)):\n",
    "    colors_rgba.append('rgba'+str(colors[i])[:-1]+','+str(opacity)+')')\n",
    "\n",
    "for i in range(len(colors_solid)):\n",
    "    colors_solid_rgba.append('rgba'+str(colors_solid[i])[:-1]+','+str(opacity)+')')\n",
    "\n",
    "# For each label there is, plot every series with that label\n",
    "for label in set(labels_fixed):\n",
    "    cluster = []\n",
    "    \n",
    "    # Plot for the labels\n",
    "    for i in range(len(labels_fixed)):\n",
    "        if(labels_fixed[i]==label):\n",
    "            \n",
    "            # Cluster colors\n",
    "            if label==0:\n",
    "                line_color = colors_rgba[0]\n",
    "                solid_color = colors_solid_rgba[0]\n",
    "            elif label==1:\n",
    "                line_color = colors_rgba[1]\n",
    "                solid_color = colors_solid_rgba[1]\n",
    "            elif label==2:\n",
    "                line_color = colors_rgba[2]\n",
    "                solid_color = colors_solid_rgba[2]\n",
    "            else:\n",
    "                line_color = colors_rgba[3]\n",
    "                solid_color = colors_solid_rgba[3]\n",
    "            \n",
    "            # Add trace\n",
    "            fig.add_trace(go.Scatter(x=time, y=mySeriesDrop_savgol[i],\n",
    "                                     mode='lines',\n",
    "                                     name=f\"Cluster {label}\",\n",
    "                                     line_color=line_color,#'rgba(130,179,196,0.12)',\n",
    "                                     showlegend=False),\n",
    "                          row=row_i+1, col=column_j+1)\n",
    "            cluster.append(mySeriesDrop_savgol[i]) # Append the series to take the average\n",
    "    \n",
    "    # Plot the average within the cluster\n",
    "    if len(cluster) > 0:\n",
    "        fig.add_trace(go.Scatter(x=time,y=np.average(np.vstack(cluster),axis=0),\n",
    "                                 mode='lines',\n",
    "                                 name=f'Cluster {label}',\n",
    "                                 line_color='black',#'rgb(57,103,119)',\n",
    "                                 showlegend=False),\n",
    "                      row=row_i+1, col=column_j+1)\n",
    "    \n",
    "    # Go to the next row, column\n",
    "    column_j+=1\n",
    "    if column_j%plot_count == 0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "\n",
    "# Update the figure\n",
    "fig.update_yaxes(range=[-0.1,1.1])#, row=x+1, col=y+1)\n",
    "fig.update_layout(font_family='Arial')\n",
    "\n",
    "# Save the figure\n",
    "pio.write_image(fig, filedirname+'TimeSeriesKMeans_4clusters_dtw_2.png', width=1*600, height=600, scale=15)\n",
    "      \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4f1dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:41:59.567815Z",
     "start_time": "2022-12-15T12:41:59.552815Z"
    }
   },
   "outputs": [],
   "source": [
    "type(labels_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab28fd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:46:10.677470Z",
     "start_time": "2022-12-15T12:46:10.000697Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count for each cluster\n",
    "cluster_c = [len(labels_fixed[labels_fixed==i]) for i in range(cluster_count)]\n",
    "cluster_n = [\"cluster_\"+str(i) for i in range(cluster_count)]\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Plot the bar plot of cluster distribution\n",
    "fig = px.bar(x=cluster_n, y=cluster_c,labels=dict(x='Clusters',y='Count'))\n",
    "\n",
    "fig.update_layout(font_family='Arial')\n",
    "fig.update_traces(marker_color='rgba(57,103,119,0.7)')\n",
    "\n",
    "# Save the figure\n",
    "pio.write_image(fig, filedirname+'distribution_TimeSeriesKMeans_4clusters_v_2.png',\n",
    "                width=1*400, height=400, scale=16)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3dacff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:46:22.871992Z",
     "start_time": "2022-12-15T12:46:22.211732Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Plot horizontal distribution\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    y=cluster_n,\n",
    "    x=cluster_c,\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color= 'rgba(57,103,119,0.7)',\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(font_family='Arial',\n",
    "                  xaxis=dict(title='Count'),\n",
    "                  yaxis=dict(title='Cluster'))\n",
    "\n",
    "# Save the figure\n",
    "pio.write_image(fig, filedirname+'distribution_TimeSeriesKMeans_4clusters_h_2.png',\n",
    "                width=1*400, height=1*400, scale=16)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93812ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:46:45.742414Z",
     "start_time": "2022-12-15T12:46:45.664367Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save the clustering results in one dataframe\n",
    "fancy_names_for_labels = [f\"{label}\" for label in labels_fixed]\n",
    "result = pd.DataFrame(zip(mySeries['Filename'],mySeries['Pixel'],mySeries['SampleNumber'],fancy_names_for_labels),\n",
    "                      columns=[\"Series\",'Pixel',\"SampleNumber\",\"Cluster\"]).sort_values(by=\"Cluster\")#.set_index(\"Series\")\n",
    "\n",
    "result['PCE_before_x'] = PCE_df['PCE_before_x']\n",
    "result['PCE_before_ceil_x'] = PCE_df['PCE_before_ceil_x']\n",
    "result['PCE_before_median_x'] = PCE_df['PCE_before_median_x']\n",
    "result['PCE_before_mean_x'] = PCE_df['PCE_before_mean_x']\n",
    "\n",
    "# Save the results as csv\n",
    "(result.sort_index()).to_csv(filedirname+'TimeSeriesKMeans_DTW_4clusters_newdata_2.csv')\n",
    "(result.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d53680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T12:46:54.948169Z",
     "start_time": "2022-12-15T12:46:54.237897Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the distribution\n",
    "\n",
    "colormap_cluster = {\"0\": \"#045a8d\",\n",
    "                    \"1\": \"#2b8cbe\",\n",
    "                    \"2\": \"#74a9cf\",\n",
    "                    \"3\": \"#bdc9e1\"}\n",
    "\n",
    "# Colormap cluster\n",
    "colormap_cluster = {\"0\": px.colors.qualitative.Antique[4],\n",
    "                    \"1\": px.colors.qualitative.Antique[9],\n",
    "                    \"2\": px.colors.qualitative.Antique[6],\n",
    "                    \"3\": px.colors.qualitative.Antique[8]}\n",
    "\n",
    "# Plot the figure\n",
    "fig = px.histogram(result.sort_values(by=['Cluster','PCE_before_ceil_x']),\n",
    "                   x=\"PCE_before_x\", color='Cluster',\n",
    "                   color_discrete_map=colormap_cluster, opacity=0.75,\n",
    "                  )\n",
    "\n",
    "# fig.update_traces(xbins_size=2)\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Max. PCE Group\",#xaxis=dict(range=[9,26]),\n",
    "                  yaxis_title=\"Count\", font_family='Arial',barnorm='fraction',\n",
    "                  bargap=0.1)\n",
    "\n",
    "pio.write_image(fig, filedirname+'TimeSeriesKMeans_4clusters_fraction_3_2.png',\n",
    "                width=1*400, height=1*400, scale=16)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa63ef9",
   "metadata": {},
   "source": [
    "## 5. Side notes/ figures\n",
    "\n",
    "### 5.1. The number of each cluster for each max. PCE group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f155043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:04:53.601911Z",
     "start_time": "2023-08-16T14:04:53.557853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data of interest\n",
    "cluster_PCE_int = pd.read_csv(filedirname+'clusters.csv').drop(['Unnamed: 0'],axis=1)\n",
    "PCE_df_group_int = pd.read_csv('dataset/PCE_df_grouping.csv')\n",
    "PCE_df_group_int_sort = (PCE_df_group_int.sort_values('Unnamed: 0')).reset_index()\n",
    "\n",
    "cluster_PCE_int['PCE_delta']=PCE_df_group_int_sort['PCE_delta']\n",
    "PCE_df_group_int_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d6c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:04:57.473529Z",
     "start_time": "2023-08-16T14:04:57.430744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group of interest calculation\n",
    "\n",
    "for i in range(4): # Clusters\n",
    "    for j in range(5): # PCE_before_x\n",
    "        count = cluster_PCE_int.loc[(cluster_PCE_int['Cluster']==i)&(cluster_PCE_int['PCE_before_x']==j+1)]\n",
    "        print('For cluster: ',i, ' and PCE_before_x: ',j+1,\n",
    "              '# data points:', count.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c758d07",
   "metadata": {},
   "source": [
    "### 5.2. Histogram cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbe7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:04:59.209811Z",
     "start_time": "2023-08-16T14:04:59.185809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grouping the data\n",
    "cluster_1 = cluster_PCE_int['PCE_delta'].loc[(cluster_PCE_int['Cluster']==0)]\n",
    "cluster_2 = cluster_PCE_int['PCE_delta'].loc[(cluster_PCE_int['Cluster']==1)]\n",
    "cluster_3 = cluster_PCE_int['PCE_delta'].loc[(cluster_PCE_int['Cluster']==2)]\n",
    "cluster_4 = cluster_PCE_int['PCE_delta'].loc[(cluster_PCE_int['Cluster']==3)]\n",
    "\n",
    "# Colors, labels, and data for plotting\n",
    "hist_data = [cluster_1, cluster_2, cluster_3, cluster_4]\n",
    "group_labels = ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4']\n",
    "colors = [px.colors.qualitative.Antique[4],\n",
    "          px.colors.qualitative.Antique[9],\n",
    "          px.colors.qualitative.Antique[6],\n",
    "          px.colors.qualitative.Antique[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c9faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:05:29.345596Z",
     "start_time": "2023-08-16T14:05:23.086905Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=2.5,\n",
    "                         colors=colors)\n",
    "\n",
    "fig.update_layout(font_family='Arial')\n",
    "pio.write_image(fig, filedirname+'rug_dist_PCE_delta.png',\n",
    "                width=1*900, height=1*400, scale=12)\n",
    "pio.write_image(fig, filedirname+'rug_dist_PCE_delta_2.png',\n",
    "                width=1*600, height=1*400, scale=12)\n",
    "fig.show()\n",
    "\n",
    "# Create distplot inset (the top)\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=2.5,\n",
    "                         colors=colors)\n",
    "\n",
    "fig.update_layout(font_family='Arial')\n",
    "fig.update_xaxes(range=[-2,90])\n",
    "fig.update_yaxes(range=[-0.005,0.07])\n",
    "pio.write_image(fig, filedirname+'rug_dist_PCE_delta_inset_top.png',\n",
    "                width=1*900, height=1*400, scale=12)\n",
    "pio.write_image(fig, filedirname+'rug_dist_PCE_delta_inset_top_2.png',\n",
    "                width=1*600, height=1*400, scale=12)\n",
    "fig.show()\n",
    "\n",
    "# Create distplot inset (the bottom)\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=2.5,\n",
    "                         colors=colors)\n",
    "\n",
    "fig.update_layout(font_family='Arial')\n",
    "fig.update_xaxes(range=[-2,90])\n",
    "pio.write_image(fig, filedirname+'rug_dist_PCE_delta_inset_bottom.png',\n",
    "                width=1*900, height=1*400, scale=12)\n",
    "pio.write_image(fig, filedirname+'rug_dist_PCE_delta_inset_bottom_2.png',\n",
    "                width=1*600, height=1*400, scale=12)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26043cdd",
   "metadata": {},
   "source": [
    "### 5.3. Quantization error SOM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99731a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:05:35.851155Z",
     "start_time": "2023-08-16T14:05:35.832188Z"
    }
   },
   "outputs": [],
   "source": [
    "# These values are generated by trying out different combinations for\n",
    "# som_x and som_y in the main part of the code\n",
    "x = np.array((2,3,4,5,6,7,8,9,10))\n",
    "\n",
    "y = np.array((3.4653711937400833,\n",
    "              2.7734776665323935,\n",
    "              (2.4188140391965622+2.4188140345317097)/2,\n",
    "              1.97200974884117,\n",
    "              (1.8233955273321616+1.823395449115016)/2,\n",
    "              1.791192306527944,\n",
    "              (1.6143132145605121+1.6141542228347283)/2,\n",
    "              (1.5764475628465437+1.5582839343215373)/2,\n",
    "              (1.4706708588067163+1.4986430155342734)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a956aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:05:37.010045Z",
     "start_time": "2023-08-16T14:05:36.641725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot quantization error\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    mode='lines+markers',\n",
    "    line=dict(color='rgb(5,112,176)'),\n",
    "))\n",
    "\n",
    "fig.update_layout(font_family='Arial',\n",
    "                  xaxis=dict(title='Number of clusters'),\n",
    "                  yaxis=dict(title='Quantization error'))\n",
    "\n",
    "# Save the figure\n",
    "pio.write_image(fig, filedirname+'som_quantizationError_result_cluster_2_10_mySeriesDrop_savgol.png',\n",
    "                width=1*300, height=1*300, scale=16)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ef377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
